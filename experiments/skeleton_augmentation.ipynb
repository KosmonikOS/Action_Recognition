{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ab9eb1",
   "metadata": {},
   "source": [
    "# Notebook with demostration of different methods for augmentation of skeletons that we get from videos with people doing exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kwargs):\n",
    "        return x\n",
    "\n",
    "def ensure_dir(path: Path) -> None:\n",
    "    path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab73f66",
   "metadata": {},
   "source": [
    "### Skeleton augmentations\n",
    "\n",
    "Assumed skeleton array shape: (T, J, 2) — per-frame 2D joints in pixels.\n",
    "We implement:\n",
    "- Rotate around image center\n",
    "- Scale from center\n",
    "- Translate (pixels)\n",
    "- Jitter (Gaussian noise)\n",
    "- Horizontal flip (W-known)\n",
    "- Temporal resample/crop\n",
    "\n",
    "If original image width `W` isn’t known, either provide it or normalize skeletons to [-1, 1] first, then flip via x -> -x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4f44de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ImageInfo:\n",
    "    width: int\n",
    "    height: int\n",
    "\n",
    "\n",
    "def skel_rotate(skel: np.ndarray, angle_deg: float, img: ImageInfo) -> np.ndarray:\n",
    "    cx, cy = img.width / 2.0, img.height / 2.0\n",
    "    theta = np.deg2rad(angle_deg)\n",
    "    R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "    centered = skel - np.array([[cx, cy]], dtype=np.float32)\n",
    "    rot = centered @ R.T\n",
    "    return rot + np.array([[cx, cy]], dtype=np.float32)\n",
    "\n",
    "\n",
    "def skel_scale(skel: np.ndarray, scale: float, img: ImageInfo) -> np.ndarray:\n",
    "    cx, cy = img.width / 2.0, img.height / 2.0\n",
    "    centered = skel - np.array([[cx, cy]], dtype=np.float32)\n",
    "    scaled = centered * scale\n",
    "    return scaled + np.array([[cx, cy]], dtype=np.float32)\n",
    "\n",
    "\n",
    "def skel_translate(skel: np.ndarray, dx: float, dy: float) -> np.ndarray:\n",
    "    return skel + np.array([[dx, dy]], dtype=np.float32)\n",
    "\n",
    "\n",
    "def skel_jitter(skel: np.ndarray, sigma: float=2.0) -> np.ndarray:\n",
    "    noise = np.random.normal(0, sigma, size=skel.shape).astype(np.float32)\n",
    "    return skel + noise\n",
    "\n",
    "\n",
    "def skel_flip_horizontal(skel: np.ndarray, img: ImageInfo) -> np.ndarray:\n",
    "    out = skel.copy()\n",
    "    out[..., 0] = (img.width - 1) - out[..., 0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def skel_time_crop(skel: np.ndarray, ratio: float=0.8) -> np.ndarray:\n",
    "    T = skel.shape[0]\n",
    "    new_T = max(1, int(T * ratio))\n",
    "    if new_T >= T:\n",
    "        return skel\n",
    "    start = np.random.randint(0, T - new_T + 1)\n",
    "    return skel[start:start+new_T]\n",
    "\n",
    "\n",
    "def skel_time_resample(skel: np.ndarray, new_T: int) -> np.ndarray:\n",
    "    T = skel.shape[0]\n",
    "    if new_T <= 0:\n",
    "        return skel\n",
    "    idx = np.linspace(0, T-1, new_T).round().astype(int)\n",
    "    idx = np.clip(idx, 0, T-1)\n",
    "    return skel[idx]\n",
    "\n",
    "\n",
    "def demo_skeleton_augs():\n",
    "    T, J = 10, 5\n",
    "    img = ImageInfo(width=640, height=360)\n",
    "    base = np.stack([\n",
    "        np.stack([\n",
    "            np.array([100 + t*2 + j*5, 50 + j*10], dtype=np.float32)\n",
    "            for j in range(J)\n",
    "        ], axis=0)\n",
    "        for t in range(T)\n",
    "    ], axis=0)\n",
    "\n",
    "    rot = np.stack([skel_rotate(base[t], 10.0, img) for t in range(T)], axis=0)\n",
    "    scl = np.stack([skel_scale(base[t], 1.1, img) for t in range(T)], axis=0)\n",
    "    trn = np.stack([skel_translate(base[t], 5.0, -3.0) for t in range(T)], axis=0)\n",
    "    jit = np.stack([skel_jitter(base[t], 1.5) for t in range(T)], axis=0)\n",
    "    flp = np.stack([skel_flip_horizontal(base[t], img) for t in range(T)], axis=0)\n",
    "    crp = skel_time_crop(base, 0.7)\n",
    "    rsm = skel_time_resample(base, 6)\n",
    "\n",
    "    return {\n",
    "        \"base\": base,\n",
    "        \"rot\": rot,\n",
    "        \"scale\": scl,\n",
    "        \"translate\": trn,\n",
    "        \"jitter\": jit,\n",
    "        \"flip\": flp,\n",
    "        \"time_crop\": crp,\n",
    "        \"time_resample\": rsm,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7290dc3",
   "metadata": {},
   "source": [
    "### Batch skeleton augmentation from .npy files\n",
    "\n",
    "This section loads skeleton arrays saved as `.npy` (shape (T, J, 2) or (T, J, 3) with confidence), applies selected augmentations using known frame width/height, and saves augmented copies while preserving dtype and confidence channel if present.\n",
    "\n",
    "Edit the paths and the `IMG_W`, `IMG_H` values below to match your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ae72c",
   "metadata": {},
   "source": [
    "#### How the batch skeleton augmentation (.npy) cell works\n",
    "\n",
    "1) Configuration: set `SKELETON_DIR` (where input `.npy` files live), `OUT_DIR` (where to save), and frame size `IMG_W`, `IMG_H`. The output directory is created if missing.\n",
    "2) Define `AUGS`: a dict mapping a filename suffix to a function that takes coordinates of shape (T, J, 2) and returns augmented coordinates. Included: rotate, scale, translate, jitter, horizontal flip, temporal crop, temporal resample.\n",
    "3) Scan `SKELETON_DIR` for `.npy` files.\n",
    "4) For each file:\n",
    "   - Load `arr` and validate shape (T, J, 2|3). Keep the original `dtype`.\n",
    "   - Detect confidence channel (`has_conf` when C=3). Split into `coords = arr[..., :2]` and `conf = arr[..., 2:]` if present.\n",
    "   - For each augmentation compute `aug_xy` (x,y only). If `conf` exists and the time length T changed (crop/resample), align `conf` via `skel_time_resample`, then concatenate back to get (T, J, 3). Otherwise, concatenate the original `conf`.\n",
    "   - Cast back to the original `dtype` and save to `OUT_DIR` with a suffix (e.g., `_rot10`, `_tcrop`).\n",
    "\n",
    "Result: for each input `.npy` one output per augmentation is produced; the original `dtype` is preserved; if confidence exists, the third channel is preserved as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0029910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 122.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved augmented skeletons to: /Users/victor/Documents/vs_files/Action_Recognition/data/augmented_skeletons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "SKELETON_DIR = Path(BASE_DIR / \"data/skeletons\")\n",
    "OUT_DIR = Path(BASE_DIR / \"data/augmented_skeletons\")\n",
    "IMG_W, IMG_H = 640, 360\n",
    "ensure_dir(OUT_DIR)\n",
    "\n",
    "AUGS = {\n",
    "    \"rot10\": lambda arr: np.stack([skel_rotate(arr[t, :, :2], 10.0, ImageInfo(IMG_W, IMG_H)) for t in range(arr.shape[0])], axis=0),\n",
    "    \"scale110\": lambda arr: np.stack([skel_scale(arr[t, :, :2], 1.1, ImageInfo(IMG_W, IMG_H)) for t in range(arr.shape[0])], axis=0),\n",
    "    \"trans_5_-3\": lambda arr: np.stack([skel_translate(arr[t, :, :2], 5.0, -3.0) for t in range(arr.shape[0])], axis=0),\n",
    "    \"jitter\": lambda arr: np.stack([skel_jitter(arr[t, :, :2], 1.5) for t in range(arr.shape[0])], axis=0),\n",
    "    \"flip\": lambda arr: np.stack([skel_flip_horizontal(arr[t, :, :2], ImageInfo(IMG_W, IMG_H)) for t in range(arr.shape[0])], axis=0),\n",
    "    \"tcrop\": lambda arr: skel_time_crop(arr[:, :, :2], 0.8),\n",
    "    \"tresamp6\": lambda arr: skel_time_resample(arr[:, :, :2], 6),\n",
    "}\n",
    "\n",
    "sk_files: List[Path] = []\n",
    "if SKELETON_DIR.exists():\n",
    "    sk_files = sorted([p for p in SKELETON_DIR.glob(\"*.npy\")])\n",
    "else:\n",
    "    print(\"Skeleton dir does not exist:\", SKELETON_DIR)\n",
    "\n",
    "for npy_path in tqdm(sk_files):\n",
    "    arr = np.load(npy_path)\n",
    "    if arr.ndim != 3 or arr.shape[-1] not in (2, 3):\n",
    "        print(\"Skip incompatible shape:\", npy_path, arr.shape)\n",
    "        continue\n",
    "    dtype = arr.dtype\n",
    "    has_conf = (arr.shape[-1] == 3)\n",
    "    coords = arr[..., :2].astype(np.float32)\n",
    "    conf = arr[..., 2:] if has_conf else None\n",
    "\n",
    "    for suf, fn in AUGS.items():\n",
    "        aug_xy = fn(coords)\n",
    "        if has_conf:\n",
    "            if aug_xy.shape[0] != arr.shape[0]:\n",
    "                new_T = aug_xy.shape[0]\n",
    "                conf_new = skel_time_resample(conf, new_T) if new_T != conf.shape[0] else conf\n",
    "                aug = np.concatenate([aug_xy, conf_new], axis=-1)\n",
    "            else:\n",
    "                aug = np.concatenate([aug_xy, conf], axis=-1)\n",
    "        else:\n",
    "            aug = aug_xy\n",
    "        aug = aug.astype(dtype, copy=False)\n",
    "        out_path = OUT_DIR / f\"{npy_path.stem}_{suf}.npy\"\n",
    "        ensure_dir(out_path.parent)\n",
    "        np.save(out_path, aug)\n",
    "print(\"Saved augmented skeletons to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb770f7",
   "metadata": {},
   "source": [
    "#### Test with 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "890b7378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented: 0b3c6ea5f943fbc80b9c6d20373cc3bf.npy -> /Users/victor/Documents/vs_files/Action_Recognition/data/augmented_skeletons_test\n",
      "Augmented: 0b4dd5fa651633b90bb7e4a455caaf4c.npy -> /Users/victor/Documents/vs_files/Action_Recognition/data/augmented_skeletons_test\n",
      "Augmented: 0b9d78bb7ad1f347ed0a6af7262da572.npy -> /Users/victor/Documents/vs_files/Action_Recognition/data/augmented_skeletons_test\n"
     ]
    }
   ],
   "source": [
    "# Targeted test on three skeleton files (pick first three from data/skeletons)\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "TEST_FILES = [\n",
    "    Path(BASE_DIR / \"data/skeletons/0b3c6ea5f943fbc80b9c6d20373cc3bf.npy\"),\n",
    "    Path(BASE_DIR / \"data/skeletons/0b4dd5fa651633b90bb7e4a455caaf4c.npy\"),\n",
    "    Path(BASE_DIR / \"data/skeletons/0b9d78bb7ad1f347ed0a6af7262da572.npy\"),\n",
    "]\n",
    "\n",
    "IMG_W, IMG_H = 640, 360\n",
    "OUT_DIR = Path(BASE_DIR / \"data/augmented_skeletons_test\")\n",
    "ensure_dir(OUT_DIR)\n",
    "\n",
    "for npy_path in TEST_FILES:\n",
    "    arr = np.load(npy_path)\n",
    "    if arr.ndim != 3 or arr.shape[-1] not in (2, 3):\n",
    "        print(\"Skip incompatible shape:\", npy_path, arr.shape)\n",
    "        continue\n",
    "    dtype = arr.dtype\n",
    "    has_conf = (arr.shape[-1] == 3)\n",
    "    coords = arr[..., :2].astype(np.float32)\n",
    "    conf = arr[..., 2:] if has_conf else None\n",
    "\n",
    "    for suf, fn in AUGS.items():\n",
    "        aug_xy = fn(coords)\n",
    "        if has_conf:\n",
    "            if aug_xy.shape[0] != arr.shape[0]:\n",
    "                new_T = aug_xy.shape[0]\n",
    "                conf_new = skel_time_resample(conf, new_T) if new_T != conf.shape[0] else conf\n",
    "                aug = np.concatenate([aug_xy, conf_new], axis=-1)\n",
    "            else:\n",
    "                aug = np.concatenate([aug_xy, conf], axis=-1)\n",
    "        else:\n",
    "            aug = aug_xy\n",
    "        aug = aug.astype(dtype, copy=False)\n",
    "        out_path = OUT_DIR / f\"{npy_path.stem}_{suf}.npy\"\n",
    "        np.save(out_path, aug)\n",
    "    print(\"Augmented:\", npy_path.name, \"->\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eeab1e",
   "metadata": {},
   "source": [
    "#### Check type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e1fa712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig: (49, 17, 3) float32\n",
      "0b3c6ea5f943fbc80b9c6d20373cc3bf_flip.npy -> (49, 17, 3) float32\n",
      "0b3c6ea5f943fbc80b9c6d20373cc3bf_jitter.npy -> (49, 17, 3) float32\n",
      "0b3c6ea5f943fbc80b9c6d20373cc3bf_rot10.npy -> (49, 17, 3) float32\n",
      "0b3c6ea5f943fbc80b9c6d20373cc3bf_scale110.npy -> (49, 17, 3) float32\n",
      "0b3c6ea5f943fbc80b9c6d20373cc3bf_tcrop.npy -> (39, 17, 3) float32\n",
      "0b3c6ea5f943fbc80b9c6d20373cc3bf_trans_5_-3.npy -> (49, 17, 3) float32\n",
      "0b3c6ea5f943fbc80b9c6d20373cc3bf_tresamp6.npy -> (6, 17, 3) float32\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "orig = Path(BASE_DIR / \"data/skeletons/0b3c6ea5f943fbc80b9c6d20373cc3bf.npy\")\n",
    "\n",
    "IMG_W, IMG_H = 640, 360\n",
    "out_dir = Path(BASE_DIR / \"data/augmented_skeletons_test\")\n",
    "aug_paths = sorted(out_dir.glob(f\"{orig.stem}_*.npy\"))\n",
    "\n",
    "arr0 = np.load(orig)\n",
    "T0, J0, C0 = arr0.shape\n",
    "print(\"orig:\", arr0.shape, arr0.dtype)\n",
    "\n",
    "for p in aug_paths:\n",
    "    arr = np.load(p)\n",
    "    print(p.name, \"->\", arr.shape, arr.dtype)\n",
    "    if \"_tcrop\" in p.stem:\n",
    "        assert arr.shape[0] < T0\n",
    "    elif \"_tresamp6\" in p.stem:\n",
    "        assert arr.shape[0] == 6\n",
    "    else:\n",
    "        assert arr.shape[0] == T0\n",
    "    if C0 == 3:\n",
    "        assert arr.shape[2] == 3\n",
    "    else:\n",
    "        assert arr.shape[2] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baabdd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 17, 3)\n",
      "First frame (orig):\n",
      "[[1.71322098e+02 1.21599564e+02 9.88917470e-01]\n",
      " [1.76614304e+02 1.18680008e+02 9.85222280e-01]\n",
      " [1.68325943e+02 1.18370483e+02 9.20247972e-01]\n",
      " [1.87045685e+02 1.22255722e+02 9.36038315e-01]\n",
      " [1.66081482e+02 1.21657700e+02 3.41832161e-01]\n",
      " [1.98538727e+02 1.39886856e+02 9.89978433e-01]\n",
      " [1.57727875e+02 1.38593582e+02 9.80428636e-01]\n",
      " [2.17625824e+02 1.06342621e+02 9.63149011e-01]\n",
      " [1.43540894e+02 1.04614494e+02 9.57552075e-01]\n",
      " [2.20913544e+02 7.39672165e+01 9.40750062e-01]\n",
      " [1.44039810e+02 7.45982971e+01 9.43886578e-01]\n",
      " [1.85741470e+02 2.15389664e+02 8.91559243e-01]\n",
      " [1.56021591e+02 2.14411423e+02 8.84795666e-01]\n",
      " [1.92367172e+02 2.40000000e+02 1.20780841e-01]\n",
      " [1.47710693e+02 2.40000000e+02 1.21171385e-01]\n",
      " [1.92333771e+02 2.22976364e+02 7.96720199e-03]\n",
      " [1.55217239e+02 2.26019165e+02 8.34085606e-03]]\n",
      "[171.3221     121.59956      0.98891747]\n",
      "(49, 17, 3)\n",
      "\n",
      "First frame (augmented):\n",
      "[[4.67677917e+02 1.21599564e+02 9.88917470e-01]\n",
      " [4.62385681e+02 1.18680008e+02 9.85222280e-01]\n",
      " [4.70674072e+02 1.18370483e+02 9.20247972e-01]\n",
      " [4.51954315e+02 1.22255722e+02 9.36038315e-01]\n",
      " [4.72918518e+02 1.21657700e+02 3.41832161e-01]\n",
      " [4.40461273e+02 1.39886856e+02 9.89978433e-01]\n",
      " [4.81272125e+02 1.38593582e+02 9.80428636e-01]\n",
      " [4.21374176e+02 1.06342621e+02 9.63149011e-01]\n",
      " [4.95459106e+02 1.04614494e+02 9.57552075e-01]\n",
      " [4.18086456e+02 7.39672165e+01 9.40750062e-01]\n",
      " [4.94960205e+02 7.45982971e+01 9.43886578e-01]\n",
      " [4.53258545e+02 2.15389664e+02 8.91559243e-01]\n",
      " [4.82978394e+02 2.14411423e+02 8.84795666e-01]\n",
      " [4.46632812e+02 2.40000000e+02 1.20780841e-01]\n",
      " [4.91289307e+02 2.40000000e+02 1.21171385e-01]\n",
      " [4.46666229e+02 2.22976364e+02 7.96720199e-03]\n",
      " [4.83782776e+02 2.26019165e+02 8.34085606e-03]]\n",
      "[467.67792    121.59956      0.98891747]\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "data = np.load(BASE_DIR / \"data/skeletons/0b3c6ea5f943fbc80b9c6d20373cc3bf.npy\")\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "print(\"First frame (orig):\")\n",
    "print(data[0]) \n",
    "print(data[0, 0])\n",
    "\n",
    "data1 = np.load(BASE_DIR / \"data/augmented_skeletons_test/0b3c6ea5f943fbc80b9c6d20373cc3bf_flip.npy\")\n",
    "\n",
    "print(data1.shape)\n",
    "\n",
    "print(\"\\nFirst frame (augmented):\")\n",
    "print(data1[0]) \n",
    "print(data1[0, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
