{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23c7fc7",
   "metadata": {},
   "source": [
    "## InfoGCN++ Training Pipeline\n",
    "This notebook mirrors the original InfoGCN++ data processing and optimisation setup for 2D skeleton `.npy` clips, making it easy to fine-tune the SODE backbone on custom datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bc7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from act_rec.datasets import SkeletonNpyDataset\n",
    "from act_rec.model.losses import LabelSmoothingCrossEntropy, masked_recon_loss\n",
    "from act_rec.model.sode import SODE\n",
    "from act_rec.training import TrainConfig, evaluate, train_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a602efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 2216 | classes: 14\n"
     ]
    }
   ],
   "source": [
    "# Paths and label mapping\n",
    "data_root = Path(\"../data/\")\n",
    "csv_path = data_root / \"skeleton_labels.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path).dropna()\n",
    "label_to_idx = {label: idx for idx, label in enumerate(sorted(df[\"label\"].unique()))}\n",
    "df[\"label_idx\"] = df[\"label\"].map(label_to_idx)\n",
    "df[\"skeleton_path\"] = df[\"skeleton_path\"].apply(lambda p: str((data_root / p).resolve()))\n",
    "print(f\"Total samples: {len(df)} | classes: {len(label_to_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59c7155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1772 | Val: 444\n"
     ]
    }
   ],
   "source": [
    "# Train/validation split\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label_idx\"],\n",
    "    random_state=42,\n",
    ")\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "train_hparams_cfg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser and schedule configuration mirroring InfoGCN++ defaults\n",
    "train_hparams = {\n",
    "    \"epochs\": 80,\n",
    "    \"base_lr\": 1e-2,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"lr_steps\": [30, 45, 60],\n",
    "    \"lr_decay\": 0.1,\n",
    "    \"grad_clip\": 1.0,\n",
    "    \"batch_size\": 32,\n",
    "    \"test_batch_size\": 64,\n",
    "    \"num_workers\": 4,\n",
    "    \"prefetch_factor\": 2,\n",
    "    \"pin_memory\": bool(torch.cuda.is_available()),\n",
    "    \"p_interval_train\": (0.5, 1.0),\n",
    "    \"p_interval_val\": (0.95,),\n",
    "    \"random_rotation\": True,\n",
    "    \"use_velocity\": False,\n",
    "    \"preload\": True,\n",
    "    \"preload_to_tensor\": True,\n",
    "    \"lambda_cls\": 1.0,\n",
    "    \"lambda_recon\": 0.1,\n",
    "    \"lambda_feature\": 0.1,\n",
    "    \"lambda_kl\": 0.0,\n",
    "    \"smoothing\": 0.1,\n",
    "    \"checkpoint_path\": \"sode_best.pt\",\n",
    "}\n",
    "\n",
    "\n",
    "def adjust_learning_rate(epoch: int, optimizer: torch.optim.Optimizer, cfg: dict) -> float:\n",
    "    \"\"\"Warm-up followed by step decay, as in the InfoGCN++ training script.\"\"\"\n",
    "    warmup = cfg[\"warmup_epochs\"]\n",
    "    base_lr = cfg[\"base_lr\"]\n",
    "    if warmup > 0 and epoch < warmup:\n",
    "        lr = base_lr * float(epoch + 1) / float(warmup)\n",
    "    else:\n",
    "        steps = cfg[\"lr_steps\"]\n",
    "        decay = cfg[\"lr_decay\"]\n",
    "        num_decays = sum(epoch >= step for step in steps)\n",
    "        lr = base_lr * (decay**num_decays)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4422344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and dataloaders mirroring InfoGCN++ feeder logic\n",
    "window_size = 64\n",
    "num_workers = train_hparams[\"num_workers\"]\n",
    "train_dataset = SkeletonNpyDataset(\n",
    "    train_df[\"skeleton_path\"].tolist(),\n",
    "    labels=train_df[\"label_idx\"].tolist(),\n",
    "    window_size=window_size,\n",
    "    p_interval=train_hparams[\"p_interval_train\"],\n",
    "    random_rotation=train_hparams[\"random_rotation\"],\n",
    "    use_velocity=train_hparams[\"use_velocity\"],\n",
    "    preload=train_hparams[\"preload\"],\n",
    "    preload_to_tensor=train_hparams[\"preload_to_tensor\"],\n",
    "    repeat=1,\n",
    ")\n",
    "val_dataset = SkeletonNpyDataset(\n",
    "    val_df[\"skeleton_path\"].tolist(),\n",
    "    labels=val_df[\"label_idx\"].tolist(),\n",
    "    window_size=window_size,\n",
    "    p_interval=train_hparams[\"p_interval_val\"],\n",
    "    random_rotation=False,\n",
    "    use_velocity=train_hparams[\"use_velocity\"],\n",
    "    preload=train_hparams[\"preload\"],\n",
    "    preload_to_tensor=train_hparams[\"preload_to_tensor\"],\n",
    ")\n",
    "\n",
    "loader_kwargs = {\n",
    "    \"num_workers\": num_workers,\n",
    "    \"pin_memory\": train_hparams[\"pin_memory\"],\n",
    "}\n",
    "if num_workers > 0:\n",
    "    loader_kwargs[\"persistent_workers\"] = True\n",
    "    loader_kwargs[\"prefetch_factor\"] = train_hparams.get(\"prefetch_factor\", 2)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_hparams[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    **loader_kwargs,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=train_hparams[\"test_batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    **loader_kwargs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df404827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80 | lr=2.0000e-03 | train_tot=4.4948 train_cls=2.3084 train_recon=2.1632 train_feat=0.0233 | val_tot=4.2209 val_cls=2.2150 val_recon=1.9871 val_feat=0.0188 val_top1=0.279 val_top5=0.777\n",
      "  -> New best checkpoint saved (top1=0.279).\n",
      "Epoch 2/80 | lr=4.0000e-03 | train_tot=2.6659 train_cls=1.9090 train_recon=0.7406 train_feat=0.0163 | val_tot=3.8897 val_cls=1.7900 val_recon=2.0400 val_feat=0.0597 val_top1=0.509 val_top5=0.910\n",
      "  -> New best checkpoint saved (top1=0.509).\n",
      "Epoch 3/80 | lr=6.0000e-03 | train_tot=2.2678 train_cls=1.6109 train_recon=0.6381 train_feat=0.0188 | val_tot=2.1688 val_cls=1.8337 val_recon=0.3246 val_feat=0.0105 val_top1=0.554 val_top5=0.937\n",
      "  -> New best checkpoint saved (top1=0.554).\n",
      "Epoch 4/80 | lr=8.0000e-03 | train_tot=1.9149 train_cls=1.4202 train_recon=0.4834 train_feat=0.0114 | val_tot=1.8180 val_cls=1.3826 val_recon=0.4124 val_feat=0.0230 val_top1=0.709 val_top5=0.971\n",
      "  -> New best checkpoint saved (top1=0.709).\n",
      "Epoch 5/80 | lr=1.0000e-02 | train_tot=1.7388 train_cls=1.2636 train_recon=0.4637 train_feat=0.0115 | val_tot=1.5345 val_cls=1.2595 val_recon=0.2674 val_feat=0.0076 val_top1=0.755 val_top5=0.964\n",
      "  -> New best checkpoint saved (top1=0.755).\n",
      "Epoch 6/80 | lr=1.0000e-02 | train_tot=1.5320 train_cls=1.1768 train_recon=0.3465 train_feat=0.0086 | val_tot=1.6232 val_cls=1.2878 val_recon=0.3274 val_feat=0.0080 val_top1=0.782 val_top5=0.971\n",
      "  -> New best checkpoint saved (top1=0.782).\n",
      "Epoch 7/80 | lr=1.0000e-02 | train_tot=1.4727 train_cls=1.0918 train_recon=0.3720 train_feat=0.0089 | val_tot=1.4258 val_cls=1.1148 val_recon=0.3033 val_feat=0.0077 val_top1=0.842 val_top5=0.973\n",
      "  -> New best checkpoint saved (top1=0.842).\n",
      "Epoch 8/80 | lr=1.0000e-02 | train_tot=1.3261 train_cls=1.0496 train_recon=0.2687 train_feat=0.0078 | val_tot=1.5883 val_cls=1.1643 val_recon=0.4165 val_feat=0.0074 val_top1=0.779 val_top5=0.980\n",
      "Epoch 9/80 | lr=1.0000e-02 | train_tot=1.3158 train_cls=1.0235 train_recon=0.2836 train_feat=0.0086 | val_tot=1.5375 val_cls=1.0419 val_recon=0.4804 val_feat=0.0152 val_top1=0.851 val_top5=0.982\n",
      "  -> New best checkpoint saved (top1=0.851).\n",
      "Epoch 10/80 | lr=1.0000e-02 | train_tot=1.2697 train_cls=0.9840 train_recon=0.2764 train_feat=0.0094 | val_tot=1.4441 val_cls=1.1166 val_recon=0.3194 val_feat=0.0081 val_top1=0.849 val_top5=0.966\n",
      "Epoch 11/80 | lr=1.0000e-02 | train_tot=1.1815 train_cls=0.9307 train_recon=0.2420 train_feat=0.0088 | val_tot=1.2356 val_cls=1.0086 val_recon=0.2192 val_feat=0.0078 val_top1=0.858 val_top5=0.980\n",
      "  -> New best checkpoint saved (top1=0.858).\n",
      "Epoch 12/80 | lr=1.0000e-02 | train_tot=1.1913 train_cls=0.9221 train_recon=0.2609 train_feat=0.0083 | val_tot=1.4043 val_cls=1.0707 val_recon=0.3239 val_feat=0.0098 val_top1=0.831 val_top5=0.980\n",
      "Epoch 13/80 | lr=1.0000e-02 | train_tot=1.1906 train_cls=0.9182 train_recon=0.2627 train_feat=0.0097 | val_tot=1.4276 val_cls=1.1178 val_recon=0.3010 val_feat=0.0089 val_top1=0.849 val_top5=0.980\n",
      "Epoch 14/80 | lr=1.0000e-02 | train_tot=1.1819 train_cls=0.8805 train_recon=0.2924 train_feat=0.0090 | val_tot=1.3313 val_cls=1.0771 val_recon=0.2460 val_feat=0.0082 val_top1=0.847 val_top5=0.984\n",
      "Epoch 15/80 | lr=1.0000e-02 | train_tot=1.1580 train_cls=0.8416 train_recon=0.3080 train_feat=0.0083 | val_tot=1.2496 val_cls=0.9880 val_recon=0.2541 val_feat=0.0075 val_top1=0.883 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.883).\n",
      "Epoch 16/80 | lr=1.0000e-02 | train_tot=1.1365 train_cls=0.8466 train_recon=0.2815 train_feat=0.0084 | val_tot=1.1144 val_cls=0.9109 val_recon=0.1961 val_feat=0.0075 val_top1=0.901 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.901).\n",
      "Epoch 17/80 | lr=1.0000e-02 | train_tot=1.0984 train_cls=0.7965 train_recon=0.2939 train_feat=0.0080 | val_tot=1.1666 val_cls=0.9943 val_recon=0.1652 val_feat=0.0072 val_top1=0.872 val_top5=0.977\n",
      "Epoch 18/80 | lr=1.0000e-02 | train_tot=1.0433 train_cls=0.8121 train_recon=0.2231 train_feat=0.0081 | val_tot=1.2199 val_cls=0.9944 val_recon=0.2186 val_feat=0.0069 val_top1=0.872 val_top5=0.989\n",
      "Epoch 19/80 | lr=1.0000e-02 | train_tot=1.0485 train_cls=0.7850 train_recon=0.2558 train_feat=0.0077 | val_tot=1.1453 val_cls=0.9442 val_recon=0.1942 val_feat=0.0068 val_top1=0.887 val_top5=0.989\n",
      "Epoch 20/80 | lr=1.0000e-02 | train_tot=1.0350 train_cls=0.7841 train_recon=0.2432 train_feat=0.0078 | val_tot=1.1157 val_cls=0.9375 val_recon=0.1711 val_feat=0.0071 val_top1=0.894 val_top5=0.986\n",
      "Epoch 21/80 | lr=1.0000e-02 | train_tot=1.0396 train_cls=0.7678 train_recon=0.2639 train_feat=0.0079 | val_tot=1.1167 val_cls=0.9305 val_recon=0.1793 val_feat=0.0069 val_top1=0.901 val_top5=0.986\n",
      "Epoch 22/80 | lr=1.0000e-02 | train_tot=1.0342 train_cls=0.7577 train_recon=0.2689 train_feat=0.0076 | val_tot=1.1590 val_cls=0.9476 val_recon=0.2047 val_feat=0.0068 val_top1=0.887 val_top5=0.982\n",
      "Epoch 23/80 | lr=1.0000e-02 | train_tot=0.9858 train_cls=0.7537 train_recon=0.2245 train_feat=0.0076 | val_tot=1.3194 val_cls=0.9209 val_recon=0.3911 val_feat=0.0075 val_top1=0.890 val_top5=0.991\n",
      "Epoch 24/80 | lr=1.0000e-02 | train_tot=1.0233 train_cls=0.7520 train_recon=0.2638 train_feat=0.0075 | val_tot=1.1578 val_cls=0.9307 val_recon=0.2205 val_feat=0.0066 val_top1=0.881 val_top5=0.991\n",
      "Epoch 25/80 | lr=1.0000e-02 | train_tot=1.0005 train_cls=0.7351 train_recon=0.2581 train_feat=0.0072 | val_tot=1.2645 val_cls=0.9412 val_recon=0.3170 val_feat=0.0063 val_top1=0.892 val_top5=0.977\n",
      "Epoch 26/80 | lr=1.0000e-02 | train_tot=1.0070 train_cls=0.7287 train_recon=0.2710 train_feat=0.0072 | val_tot=1.1853 val_cls=0.9500 val_recon=0.2292 val_feat=0.0061 val_top1=0.905 val_top5=0.982\n",
      "  -> New best checkpoint saved (top1=0.905).\n",
      "Epoch 27/80 | lr=1.0000e-02 | train_tot=0.9373 train_cls=0.7207 train_recon=0.2097 train_feat=0.0070 | val_tot=1.0904 val_cls=0.9222 val_recon=0.1619 val_feat=0.0063 val_top1=0.890 val_top5=0.984\n",
      "Epoch 28/80 | lr=1.0000e-02 | train_tot=1.0785 train_cls=0.7440 train_recon=0.3272 train_feat=0.0073 | val_tot=1.4443 val_cls=0.9531 val_recon=0.4850 val_feat=0.0063 val_top1=0.883 val_top5=0.989\n",
      "Epoch 29/80 | lr=1.0000e-02 | train_tot=0.9402 train_cls=0.7062 train_recon=0.2269 train_feat=0.0071 | val_tot=1.1588 val_cls=0.9067 val_recon=0.2460 val_feat=0.0061 val_top1=0.910 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.910).\n",
      "Epoch 30/80 | lr=1.0000e-02 | train_tot=0.9428 train_cls=0.7032 train_recon=0.2328 train_feat=0.0068 | val_tot=1.1453 val_cls=0.8860 val_recon=0.2533 val_feat=0.0060 val_top1=0.901 val_top5=0.989\n",
      "Epoch 31/80 | lr=1.0000e-03 | train_tot=0.8604 train_cls=0.6575 train_recon=0.1963 train_feat=0.0066 | val_tot=1.0381 val_cls=0.8459 val_recon=0.1866 val_feat=0.0057 val_top1=0.919 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.919).\n",
      "Epoch 32/80 | lr=1.0000e-03 | train_tot=0.8319 train_cls=0.6461 train_recon=0.1795 train_feat=0.0063 | val_tot=0.9880 val_cls=0.8403 val_recon=0.1422 val_feat=0.0055 val_top1=0.912 val_top5=0.993\n",
      "Epoch 33/80 | lr=1.0000e-03 | train_tot=0.8080 train_cls=0.6366 train_recon=0.1653 train_feat=0.0061 | val_tot=0.9868 val_cls=0.8387 val_recon=0.1429 val_feat=0.0053 val_top1=0.921 val_top5=0.993\n",
      "  -> New best checkpoint saved (top1=0.921).\n",
      "Epoch 34/80 | lr=1.0000e-03 | train_tot=0.8084 train_cls=0.6362 train_recon=0.1662 train_feat=0.0060 | val_tot=1.0001 val_cls=0.8566 val_recon=0.1384 val_feat=0.0051 val_top1=0.917 val_top5=0.991\n",
      "Epoch 35/80 | lr=1.0000e-03 | train_tot=0.8011 train_cls=0.6337 train_recon=0.1616 train_feat=0.0058 | val_tot=0.9761 val_cls=0.8335 val_recon=0.1376 val_feat=0.0050 val_top1=0.921 val_top5=0.991\n",
      "Epoch 36/80 | lr=1.0000e-03 | train_tot=0.7934 train_cls=0.6266 train_recon=0.1611 train_feat=0.0057 | val_tot=0.9903 val_cls=0.8331 val_recon=0.1522 val_feat=0.0049 val_top1=0.930 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.930).\n",
      "Epoch 37/80 | lr=1.0000e-03 | train_tot=0.7896 train_cls=0.6226 train_recon=0.1614 train_feat=0.0056 | val_tot=0.9777 val_cls=0.8374 val_recon=0.1355 val_feat=0.0048 val_top1=0.926 val_top5=0.989\n",
      "Epoch 38/80 | lr=1.0000e-03 | train_tot=0.7902 train_cls=0.6236 train_recon=0.1612 train_feat=0.0055 | val_tot=0.9930 val_cls=0.8526 val_recon=0.1356 val_feat=0.0047 val_top1=0.910 val_top5=0.991\n",
      "Epoch 39/80 | lr=1.0000e-03 | train_tot=0.7853 train_cls=0.6227 train_recon=0.1572 train_feat=0.0054 | val_tot=0.9900 val_cls=0.8427 val_recon=0.1426 val_feat=0.0047 val_top1=0.921 val_top5=0.991\n",
      "Epoch 40/80 | lr=1.0000e-03 | train_tot=0.7862 train_cls=0.6201 train_recon=0.1607 train_feat=0.0054 | val_tot=0.9893 val_cls=0.8501 val_recon=0.1347 val_feat=0.0045 val_top1=0.910 val_top5=0.991\n",
      "Epoch 41/80 | lr=1.0000e-03 | train_tot=0.7868 train_cls=0.6198 train_recon=0.1618 train_feat=0.0052 | val_tot=0.9900 val_cls=0.8522 val_recon=0.1333 val_feat=0.0045 val_top1=0.917 val_top5=0.989\n",
      "Epoch 42/80 | lr=1.0000e-03 | train_tot=0.7827 train_cls=0.6181 train_recon=0.1595 train_feat=0.0051 | val_tot=0.9774 val_cls=0.8399 val_recon=0.1331 val_feat=0.0044 val_top1=0.921 val_top5=0.989\n",
      "Epoch 43/80 | lr=1.0000e-03 | train_tot=0.7801 train_cls=0.6144 train_recon=0.1607 train_feat=0.0051 | val_tot=0.9792 val_cls=0.8421 val_recon=0.1327 val_feat=0.0044 val_top1=0.923 val_top5=0.991\n",
      "Epoch 44/80 | lr=1.0000e-03 | train_tot=0.7762 train_cls=0.6137 train_recon=0.1575 train_feat=0.0050 | val_tot=0.9962 val_cls=0.8561 val_recon=0.1358 val_feat=0.0043 val_top1=0.921 val_top5=0.989\n",
      "Epoch 45/80 | lr=1.0000e-03 | train_tot=0.7732 train_cls=0.6110 train_recon=0.1574 train_feat=0.0049 | val_tot=0.9931 val_cls=0.8511 val_recon=0.1377 val_feat=0.0042 val_top1=0.914 val_top5=0.989\n",
      "Epoch 46/80 | lr=1.0000e-04 | train_tot=0.7729 train_cls=0.6100 train_recon=0.1581 train_feat=0.0049 | val_tot=0.9725 val_cls=0.8324 val_recon=0.1358 val_feat=0.0042 val_top1=0.917 val_top5=0.989\n",
      "Epoch 47/80 | lr=1.0000e-04 | train_tot=0.7704 train_cls=0.6087 train_recon=0.1568 train_feat=0.0048 | val_tot=0.9847 val_cls=0.8484 val_recon=0.1322 val_feat=0.0042 val_top1=0.919 val_top5=0.989\n",
      "Epoch 48/80 | lr=1.0000e-04 | train_tot=0.7669 train_cls=0.6065 train_recon=0.1556 train_feat=0.0048 | val_tot=0.9726 val_cls=0.8352 val_recon=0.1333 val_feat=0.0042 val_top1=0.919 val_top5=0.991\n",
      "Epoch 49/80 | lr=1.0000e-04 | train_tot=0.7688 train_cls=0.6078 train_recon=0.1562 train_feat=0.0048 | val_tot=0.9858 val_cls=0.8497 val_recon=0.1319 val_feat=0.0042 val_top1=0.914 val_top5=0.991\n",
      "Epoch 50/80 | lr=1.0000e-04 | train_tot=0.7702 train_cls=0.6085 train_recon=0.1569 train_feat=0.0048 | val_tot=0.9742 val_cls=0.8336 val_recon=0.1364 val_feat=0.0042 val_top1=0.919 val_top5=0.991\n",
      "Epoch 51/80 | lr=1.0000e-04 | train_tot=0.7697 train_cls=0.6087 train_recon=0.1562 train_feat=0.0048 | val_tot=0.9730 val_cls=0.8341 val_recon=0.1347 val_feat=0.0042 val_top1=0.917 val_top5=0.991\n",
      "Epoch 52/80 | lr=1.0000e-04 | train_tot=0.7678 train_cls=0.6072 train_recon=0.1558 train_feat=0.0048 | val_tot=0.9792 val_cls=0.8424 val_recon=0.1326 val_feat=0.0042 val_top1=0.926 val_top5=0.991\n",
      "Epoch 53/80 | lr=1.0000e-04 | train_tot=0.7650 train_cls=0.6060 train_recon=0.1543 train_feat=0.0048 | val_tot=0.9871 val_cls=0.8510 val_recon=0.1320 val_feat=0.0042 val_top1=0.917 val_top5=0.989\n",
      "Epoch 54/80 | lr=1.0000e-04 | train_tot=0.7683 train_cls=0.6070 train_recon=0.1566 train_feat=0.0048 | val_tot=0.9722 val_cls=0.8358 val_recon=0.1323 val_feat=0.0041 val_top1=0.917 val_top5=0.991\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = train_hparams[\"epochs\"]\n",
    "best_top1 = 0.0\n",
    "history = []\n",
    "ckpt_path = Path(train_hparams[\"checkpoint_path\"])\n",
    "ckpt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lr = adjust_learning_rate(epoch, optimizer, train_hparams)\n",
    "    train_metrics = train_one_epoch(model, train_loader, optimizer, config)\n",
    "    val_metrics = evaluate(model, val_loader, config)\n",
    "    metrics = {**train_metrics, **val_metrics, \"lr\": lr}\n",
    "    history.append(metrics)\n",
    "\n",
    "    msg = (\n",
    "        f\"Epoch {epoch + 1}/{num_epochs} | lr={lr:.4e} | \"\n",
    "        f\"train_tot={train_metrics['train_total_loss']:.4f} \"\n",
    "        f\"train_cls={train_metrics['train_cls_loss']:.4f} \"\n",
    "        f\"train_recon={train_metrics['train_recon_loss']:.4f} \"\n",
    "        f\"train_feat={train_metrics['train_feature_loss']:.4f} | \"\n",
    "        f\"val_tot={val_metrics['val_total_loss']:.4f} \"\n",
    "        f\"val_cls={val_metrics['val_cls_loss']:.4f} \"\n",
    "        f\"val_recon={val_metrics['val_recon_loss']:.4f} \"\n",
    "        f\"val_feat={val_metrics['val_feature_loss']:.4f} \"\n",
    "        f\"val_top1={val_metrics['val_top1']:.3f} \"\n",
    "        f\"val_top5={val_metrics['val_top5']:.3f}\"\n",
    "    )\n",
    "    print(msg)\n",
    "\n",
    "    if val_metrics[\"val_top1\"] > best_top1:\n",
    "        best_top1 = val_metrics[\"val_top1\"]\n",
    "        torch.save({\"model\": model.state_dict(), \"label_to_idx\": label_to_idx}, ckpt_path)\n",
    "        print(f\"  -> New best checkpoint saved (top1={best_top1:.3f}).\")\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3e1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimisation setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "model = SODE(\n",
    "    num_class=len(label_to_idx),\n",
    "    num_point=17,\n",
    "    num_person=1,\n",
    "    graph=\"act_rec.graph.coco.Graph\",\n",
    "    in_channels=3,\n",
    "    T=window_size,\n",
    "    n_step=3,\n",
    "    num_cls=4,\n",
    ").to(device)\n",
    "\n",
    "opt_name = train_hparams[\"optimizer\"].lower()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=train_hparams[\"base_lr\"],\n",
    "    weight_decay=train_hparams[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "config = TrainConfig(\n",
    "    device=device,\n",
    "    cls_loss=LabelSmoothingCrossEntropy(smoothing=train_hparams[\"smoothing\"]),\n",
    "    lambda_cls=train_hparams[\"lambda_cls\"],\n",
    "    lambda_recon=train_hparams[\"lambda_recon\"],\n",
    "    lambda_feature=train_hparams[\"lambda_feature\"],\n",
    "    lambda_kl=train_hparams[\"lambda_kl\"],\n",
    "    n_step=model.n_step,\n",
    "    recon_loss_fn=masked_recon_loss,\n",
    "    feature_loss_fn=masked_recon_loss,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e98687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80 | lr=2.0000e-03 | train_tot=4.4948 train_cls=2.3084 train_recon=2.1632 train_feat=0.0233 | val_tot=4.2209 val_cls=2.2150 val_recon=1.9871 val_feat=0.0188 val_top1=0.279 val_top5=0.777\n",
      "  -> New best checkpoint saved (top1=0.279).\n",
      "Epoch 2/80 | lr=4.0000e-03 | train_tot=2.6659 train_cls=1.9090 train_recon=0.7406 train_feat=0.0163 | val_tot=3.8897 val_cls=1.7900 val_recon=2.0400 val_feat=0.0597 val_top1=0.509 val_top5=0.910\n",
      "  -> New best checkpoint saved (top1=0.509).\n",
      "Epoch 3/80 | lr=6.0000e-03 | train_tot=2.2678 train_cls=1.6109 train_recon=0.6381 train_feat=0.0188 | val_tot=2.1688 val_cls=1.8337 val_recon=0.3246 val_feat=0.0105 val_top1=0.554 val_top5=0.937\n",
      "  -> New best checkpoint saved (top1=0.554).\n",
      "Epoch 4/80 | lr=8.0000e-03 | train_tot=1.9149 train_cls=1.4202 train_recon=0.4834 train_feat=0.0114 | val_tot=1.8180 val_cls=1.3826 val_recon=0.4124 val_feat=0.0230 val_top1=0.709 val_top5=0.971\n",
      "  -> New best checkpoint saved (top1=0.709).\n",
      "Epoch 5/80 | lr=1.0000e-02 | train_tot=1.7388 train_cls=1.2636 train_recon=0.4637 train_feat=0.0115 | val_tot=1.5345 val_cls=1.2595 val_recon=0.2674 val_feat=0.0076 val_top1=0.755 val_top5=0.964\n",
      "  -> New best checkpoint saved (top1=0.755).\n",
      "Epoch 6/80 | lr=1.0000e-02 | train_tot=1.5320 train_cls=1.1768 train_recon=0.3465 train_feat=0.0086 | val_tot=1.6232 val_cls=1.2878 val_recon=0.3274 val_feat=0.0080 val_top1=0.782 val_top5=0.971\n",
      "  -> New best checkpoint saved (top1=0.782).\n",
      "Epoch 7/80 | lr=1.0000e-02 | train_tot=1.4727 train_cls=1.0918 train_recon=0.3720 train_feat=0.0089 | val_tot=1.4258 val_cls=1.1148 val_recon=0.3033 val_feat=0.0077 val_top1=0.842 val_top5=0.973\n",
      "  -> New best checkpoint saved (top1=0.842).\n",
      "Epoch 8/80 | lr=1.0000e-02 | train_tot=1.3261 train_cls=1.0496 train_recon=0.2687 train_feat=0.0078 | val_tot=1.5883 val_cls=1.1643 val_recon=0.4165 val_feat=0.0074 val_top1=0.779 val_top5=0.980\n",
      "Epoch 9/80 | lr=1.0000e-02 | train_tot=1.3158 train_cls=1.0235 train_recon=0.2836 train_feat=0.0086 | val_tot=1.5375 val_cls=1.0419 val_recon=0.4804 val_feat=0.0152 val_top1=0.851 val_top5=0.982\n",
      "  -> New best checkpoint saved (top1=0.851).\n",
      "Epoch 10/80 | lr=1.0000e-02 | train_tot=1.2697 train_cls=0.9840 train_recon=0.2764 train_feat=0.0094 | val_tot=1.4441 val_cls=1.1166 val_recon=0.3194 val_feat=0.0081 val_top1=0.849 val_top5=0.966\n",
      "Epoch 11/80 | lr=1.0000e-02 | train_tot=1.1815 train_cls=0.9307 train_recon=0.2420 train_feat=0.0088 | val_tot=1.2356 val_cls=1.0086 val_recon=0.2192 val_feat=0.0078 val_top1=0.858 val_top5=0.980\n",
      "  -> New best checkpoint saved (top1=0.858).\n",
      "Epoch 12/80 | lr=1.0000e-02 | train_tot=1.1913 train_cls=0.9221 train_recon=0.2609 train_feat=0.0083 | val_tot=1.4043 val_cls=1.0707 val_recon=0.3239 val_feat=0.0098 val_top1=0.831 val_top5=0.980\n",
      "Epoch 13/80 | lr=1.0000e-02 | train_tot=1.1906 train_cls=0.9182 train_recon=0.2627 train_feat=0.0097 | val_tot=1.4276 val_cls=1.1178 val_recon=0.3010 val_feat=0.0089 val_top1=0.849 val_top5=0.980\n",
      "Epoch 14/80 | lr=1.0000e-02 | train_tot=1.1819 train_cls=0.8805 train_recon=0.2924 train_feat=0.0090 | val_tot=1.3313 val_cls=1.0771 val_recon=0.2460 val_feat=0.0082 val_top1=0.847 val_top5=0.984\n",
      "Epoch 15/80 | lr=1.0000e-02 | train_tot=1.1580 train_cls=0.8416 train_recon=0.3080 train_feat=0.0083 | val_tot=1.2496 val_cls=0.9880 val_recon=0.2541 val_feat=0.0075 val_top1=0.883 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.883).\n",
      "Epoch 16/80 | lr=1.0000e-02 | train_tot=1.1365 train_cls=0.8466 train_recon=0.2815 train_feat=0.0084 | val_tot=1.1144 val_cls=0.9109 val_recon=0.1961 val_feat=0.0075 val_top1=0.901 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.901).\n",
      "Epoch 17/80 | lr=1.0000e-02 | train_tot=1.0984 train_cls=0.7965 train_recon=0.2939 train_feat=0.0080 | val_tot=1.1666 val_cls=0.9943 val_recon=0.1652 val_feat=0.0072 val_top1=0.872 val_top5=0.977\n",
      "Epoch 18/80 | lr=1.0000e-02 | train_tot=1.0433 train_cls=0.8121 train_recon=0.2231 train_feat=0.0081 | val_tot=1.2199 val_cls=0.9944 val_recon=0.2186 val_feat=0.0069 val_top1=0.872 val_top5=0.989\n",
      "Epoch 19/80 | lr=1.0000e-02 | train_tot=1.0485 train_cls=0.7850 train_recon=0.2558 train_feat=0.0077 | val_tot=1.1453 val_cls=0.9442 val_recon=0.1942 val_feat=0.0068 val_top1=0.887 val_top5=0.989\n",
      "Epoch 20/80 | lr=1.0000e-02 | train_tot=1.0350 train_cls=0.7841 train_recon=0.2432 train_feat=0.0078 | val_tot=1.1157 val_cls=0.9375 val_recon=0.1711 val_feat=0.0071 val_top1=0.894 val_top5=0.986\n",
      "Epoch 21/80 | lr=1.0000e-02 | train_tot=1.0396 train_cls=0.7678 train_recon=0.2639 train_feat=0.0079 | val_tot=1.1167 val_cls=0.9305 val_recon=0.1793 val_feat=0.0069 val_top1=0.901 val_top5=0.986\n",
      "Epoch 22/80 | lr=1.0000e-02 | train_tot=1.0342 train_cls=0.7577 train_recon=0.2689 train_feat=0.0076 | val_tot=1.1590 val_cls=0.9476 val_recon=0.2047 val_feat=0.0068 val_top1=0.887 val_top5=0.982\n",
      "Epoch 23/80 | lr=1.0000e-02 | train_tot=0.9858 train_cls=0.7537 train_recon=0.2245 train_feat=0.0076 | val_tot=1.3194 val_cls=0.9209 val_recon=0.3911 val_feat=0.0075 val_top1=0.890 val_top5=0.991\n",
      "Epoch 24/80 | lr=1.0000e-02 | train_tot=1.0233 train_cls=0.7520 train_recon=0.2638 train_feat=0.0075 | val_tot=1.1578 val_cls=0.9307 val_recon=0.2205 val_feat=0.0066 val_top1=0.881 val_top5=0.991\n",
      "Epoch 25/80 | lr=1.0000e-02 | train_tot=1.0005 train_cls=0.7351 train_recon=0.2581 train_feat=0.0072 | val_tot=1.2645 val_cls=0.9412 val_recon=0.3170 val_feat=0.0063 val_top1=0.892 val_top5=0.977\n",
      "Epoch 26/80 | lr=1.0000e-02 | train_tot=1.0070 train_cls=0.7287 train_recon=0.2710 train_feat=0.0072 | val_tot=1.1853 val_cls=0.9500 val_recon=0.2292 val_feat=0.0061 val_top1=0.905 val_top5=0.982\n",
      "  -> New best checkpoint saved (top1=0.905).\n",
      "Epoch 27/80 | lr=1.0000e-02 | train_tot=0.9373 train_cls=0.7207 train_recon=0.2097 train_feat=0.0070 | val_tot=1.0904 val_cls=0.9222 val_recon=0.1619 val_feat=0.0063 val_top1=0.890 val_top5=0.984\n",
      "Epoch 28/80 | lr=1.0000e-02 | train_tot=1.0785 train_cls=0.7440 train_recon=0.3272 train_feat=0.0073 | val_tot=1.4443 val_cls=0.9531 val_recon=0.4850 val_feat=0.0063 val_top1=0.883 val_top5=0.989\n",
      "Epoch 29/80 | lr=1.0000e-02 | train_tot=0.9402 train_cls=0.7062 train_recon=0.2269 train_feat=0.0071 | val_tot=1.1588 val_cls=0.9067 val_recon=0.2460 val_feat=0.0061 val_top1=0.910 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.910).\n",
      "Epoch 30/80 | lr=1.0000e-02 | train_tot=0.9428 train_cls=0.7032 train_recon=0.2328 train_feat=0.0068 | val_tot=1.1453 val_cls=0.8860 val_recon=0.2533 val_feat=0.0060 val_top1=0.901 val_top5=0.989\n",
      "Epoch 31/80 | lr=1.0000e-03 | train_tot=0.8604 train_cls=0.6575 train_recon=0.1963 train_feat=0.0066 | val_tot=1.0381 val_cls=0.8459 val_recon=0.1866 val_feat=0.0057 val_top1=0.919 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.919).\n",
      "Epoch 32/80 | lr=1.0000e-03 | train_tot=0.8319 train_cls=0.6461 train_recon=0.1795 train_feat=0.0063 | val_tot=0.9880 val_cls=0.8403 val_recon=0.1422 val_feat=0.0055 val_top1=0.912 val_top5=0.993\n",
      "Epoch 33/80 | lr=1.0000e-03 | train_tot=0.8080 train_cls=0.6366 train_recon=0.1653 train_feat=0.0061 | val_tot=0.9868 val_cls=0.8387 val_recon=0.1429 val_feat=0.0053 val_top1=0.921 val_top5=0.993\n",
      "  -> New best checkpoint saved (top1=0.921).\n",
      "Epoch 34/80 | lr=1.0000e-03 | train_tot=0.8084 train_cls=0.6362 train_recon=0.1662 train_feat=0.0060 | val_tot=1.0001 val_cls=0.8566 val_recon=0.1384 val_feat=0.0051 val_top1=0.917 val_top5=0.991\n",
      "Epoch 35/80 | lr=1.0000e-03 | train_tot=0.8011 train_cls=0.6337 train_recon=0.1616 train_feat=0.0058 | val_tot=0.9761 val_cls=0.8335 val_recon=0.1376 val_feat=0.0050 val_top1=0.921 val_top5=0.991\n",
      "Epoch 36/80 | lr=1.0000e-03 | train_tot=0.7934 train_cls=0.6266 train_recon=0.1611 train_feat=0.0057 | val_tot=0.9903 val_cls=0.8331 val_recon=0.1522 val_feat=0.0049 val_top1=0.930 val_top5=0.989\n",
      "  -> New best checkpoint saved (top1=0.930).\n",
      "Epoch 37/80 | lr=1.0000e-03 | train_tot=0.7896 train_cls=0.6226 train_recon=0.1614 train_feat=0.0056 | val_tot=0.9777 val_cls=0.8374 val_recon=0.1355 val_feat=0.0048 val_top1=0.926 val_top5=0.989\n",
      "Epoch 38/80 | lr=1.0000e-03 | train_tot=0.7902 train_cls=0.6236 train_recon=0.1612 train_feat=0.0055 | val_tot=0.9930 val_cls=0.8526 val_recon=0.1356 val_feat=0.0047 val_top1=0.910 val_top5=0.991\n",
      "Epoch 39/80 | lr=1.0000e-03 | train_tot=0.7853 train_cls=0.6227 train_recon=0.1572 train_feat=0.0054 | val_tot=0.9900 val_cls=0.8427 val_recon=0.1426 val_feat=0.0047 val_top1=0.921 val_top5=0.991\n",
      "Epoch 40/80 | lr=1.0000e-03 | train_tot=0.7862 train_cls=0.6201 train_recon=0.1607 train_feat=0.0054 | val_tot=0.9893 val_cls=0.8501 val_recon=0.1347 val_feat=0.0045 val_top1=0.910 val_top5=0.991\n",
      "Epoch 41/80 | lr=1.0000e-03 | train_tot=0.7868 train_cls=0.6198 train_recon=0.1618 train_feat=0.0052 | val_tot=0.9900 val_cls=0.8522 val_recon=0.1333 val_feat=0.0045 val_top1=0.917 val_top5=0.989\n",
      "Epoch 42/80 | lr=1.0000e-03 | train_tot=0.7827 train_cls=0.6181 train_recon=0.1595 train_feat=0.0051 | val_tot=0.9774 val_cls=0.8399 val_recon=0.1331 val_feat=0.0044 val_top1=0.921 val_top5=0.989\n",
      "Epoch 43/80 | lr=1.0000e-03 | train_tot=0.7801 train_cls=0.6144 train_recon=0.1607 train_feat=0.0051 | val_tot=0.9792 val_cls=0.8421 val_recon=0.1327 val_feat=0.0044 val_top1=0.923 val_top5=0.991\n",
      "Epoch 44/80 | lr=1.0000e-03 | train_tot=0.7762 train_cls=0.6137 train_recon=0.1575 train_feat=0.0050 | val_tot=0.9962 val_cls=0.8561 val_recon=0.1358 val_feat=0.0043 val_top1=0.921 val_top5=0.989\n",
      "Epoch 45/80 | lr=1.0000e-03 | train_tot=0.7732 train_cls=0.6110 train_recon=0.1574 train_feat=0.0049 | val_tot=0.9931 val_cls=0.8511 val_recon=0.1377 val_feat=0.0042 val_top1=0.914 val_top5=0.989\n",
      "Epoch 46/80 | lr=1.0000e-04 | train_tot=0.7729 train_cls=0.6100 train_recon=0.1581 train_feat=0.0049 | val_tot=0.9725 val_cls=0.8324 val_recon=0.1358 val_feat=0.0042 val_top1=0.917 val_top5=0.989\n",
      "Epoch 47/80 | lr=1.0000e-04 | train_tot=0.7704 train_cls=0.6087 train_recon=0.1568 train_feat=0.0048 | val_tot=0.9847 val_cls=0.8484 val_recon=0.1322 val_feat=0.0042 val_top1=0.919 val_top5=0.989\n",
      "Epoch 48/80 | lr=1.0000e-04 | train_tot=0.7669 train_cls=0.6065 train_recon=0.1556 train_feat=0.0048 | val_tot=0.9726 val_cls=0.8352 val_recon=0.1333 val_feat=0.0042 val_top1=0.919 val_top5=0.991\n",
      "Epoch 49/80 | lr=1.0000e-04 | train_tot=0.7688 train_cls=0.6078 train_recon=0.1562 train_feat=0.0048 | val_tot=0.9858 val_cls=0.8497 val_recon=0.1319 val_feat=0.0042 val_top1=0.914 val_top5=0.991\n",
      "Epoch 50/80 | lr=1.0000e-04 | train_tot=0.7702 train_cls=0.6085 train_recon=0.1569 train_feat=0.0048 | val_tot=0.9742 val_cls=0.8336 val_recon=0.1364 val_feat=0.0042 val_top1=0.919 val_top5=0.991\n",
      "Epoch 51/80 | lr=1.0000e-04 | train_tot=0.7697 train_cls=0.6087 train_recon=0.1562 train_feat=0.0048 | val_tot=0.9730 val_cls=0.8341 val_recon=0.1347 val_feat=0.0042 val_top1=0.917 val_top5=0.991\n",
      "Epoch 52/80 | lr=1.0000e-04 | train_tot=0.7678 train_cls=0.6072 train_recon=0.1558 train_feat=0.0048 | val_tot=0.9792 val_cls=0.8424 val_recon=0.1326 val_feat=0.0042 val_top1=0.926 val_top5=0.991\n",
      "Epoch 53/80 | lr=1.0000e-04 | train_tot=0.7650 train_cls=0.6060 train_recon=0.1543 train_feat=0.0048 | val_tot=0.9871 val_cls=0.8510 val_recon=0.1320 val_feat=0.0042 val_top1=0.917 val_top5=0.989\n",
      "Epoch 54/80 | lr=1.0000e-04 | train_tot=0.7683 train_cls=0.6070 train_recon=0.1566 train_feat=0.0048 | val_tot=0.9722 val_cls=0.8358 val_recon=0.1323 val_feat=0.0041 val_top1=0.917 val_top5=0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m      9\u001b[39m     lr = adjust_learning_rate(epoch, optimizer, train_hparams)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     train_metrics = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     val_metrics = evaluate(model, val_loader, config)\n\u001b[32m     12\u001b[39m     metrics = {**train_metrics, **val_metrics, \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University/CV_PMLDL_DR_Project/src/act_rec/training.py:139\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, config)\u001b[39m\n\u001b[32m    137\u001b[39m loss.backward()\n\u001b[32m    138\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m cls_meter.update(cls_loss.item(), batch_size)\n\u001b[32m    142\u001b[39m recon_meter.update(recon_loss.item(), batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/act-rec/lib/python3.11/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/act-rec/lib/python3.11/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/act-rec/lib/python3.11/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/act-rec/lib/python3.11/site-packages/torch/optim/optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/act-rec/lib/python3.11/site-packages/torch/optim/adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/act-rec/lib/python3.11/site-packages/torch/optim/adam.py:464\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    462\u001b[39m         exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[32m    467\u001b[39m     step = step_t\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/selectors.py\", line 566, in select\n",
      "    kev_list = self._selector.control(None, max_ev, timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nikita/anaconda3/envs/act-rec/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 70696) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = train_hparams[\"epochs\"]\n",
    "best_top1 = 0.0\n",
    "history = []\n",
    "ckpt_path = Path(train_hparams[\"checkpoint_path\"])\n",
    "ckpt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lr = adjust_learning_rate(epoch, optimizer, train_hparams)\n",
    "    train_metrics = train_one_epoch(model, train_loader, optimizer, config)\n",
    "    val_metrics = evaluate(model, val_loader, config)\n",
    "    metrics = {**train_metrics, **val_metrics, \"lr\": lr}\n",
    "    history.append(metrics)\n",
    "\n",
    "    msg = (\n",
    "        f\"Epoch {epoch + 1}/{num_epochs} | lr={lr:.4e} | \"\n",
    "        f\"train_tot={train_metrics['train_total_loss']:.4f} \"\n",
    "        f\"train_cls={train_metrics['train_cls_loss']:.4f} \"\n",
    "        f\"train_recon={train_metrics['train_recon_loss']:.4f} \"\n",
    "        f\"train_feat={train_metrics['train_feature_loss']:.4f} | \"\n",
    "        f\"val_tot={val_metrics['val_total_loss']:.4f} \"\n",
    "        f\"val_cls={val_metrics['val_cls_loss']:.4f} \"\n",
    "        f\"val_recon={val_metrics['val_recon_loss']:.4f} \"\n",
    "        f\"val_feat={val_metrics['val_feature_loss']:.4f} \"\n",
    "        f\"val_top1={val_metrics['val_top1']:.3f} \"\n",
    "        f\"val_top5={val_metrics['val_top5']:.3f}\"\n",
    "    )\n",
    "    print(msg)\n",
    "\n",
    "    if val_metrics[\"val_top1\"] > best_top1:\n",
    "        best_top1 = val_metrics[\"val_top1\"]\n",
    "        torch.save({\"model\": model.state_dict(), \"label_to_idx\": label_to_idx}, ckpt_path)\n",
    "        print(f\"  -> New best checkpoint saved (top1={best_top1:.3f}).\")\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history as a DataFrame for quick inspection\n",
    "pd.DataFrame(history)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
